{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[],"dockerImageVersionId":31040,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np\nfrom sklearn.neural_network import MLPClassifier\nfrom sklearn.datasets import load_digits\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import MinMaxScaler\nimport warnings\n\n# Suppress ConvergenceWarning from MLPClassifier for cleaner output\nwarnings.filterwarnings(\"ignore\", category=UserWarning, module=\"sklearn.neural_network\")\nwarnings.filterwarnings(\"ignore\", category=RuntimeWarning, message=\"overflow encountered in exp\")\nwarnings.filterwarnings(\"ignore\", category=RuntimeWarning, message=\"invalid value encountered in true_divide\")\n\n# --- Square Attack Function ---\ndef square_attack(\n    model,\n    original_input,\n    target_class,\n    epsilon=0.1,        # L-infinity norm budget for the perturbation\n    max_iterations=1000, # Total iterations for the attack\n    p_step=0.05,        # Probability of updating a square region (initial patch size relative to image size)\n    kappa=0.0           # Confidence parameter: target logit must be kappa higher than others (lower is better for attack)\n):\n    \"\"\"\n    Implements the Square Attack, a black-box adversarial attack.\n\n    The Square Attack iteratively adds square-shaped perturbations to the input,\n    estimating the effect via model queries, without needing gradients.\n\n    Args:\n        model (sklearn.base.BaseEstimator): The trained scikit-learn classification model to attack.\n                                            Must have a `predict_proba` method.\n        original_input (np.array): The initial input data (1D numpy array, values in [0, 1]).\n                                   Assumes the input can be reshaped to a square image (e.g., 8x8 for digits).\n        target_class (int): The specific class index the adversarial example should be classified as.\n        epsilon (float): Maximum allowed L-infinity norm of the perturbation.\n        max_iterations (int): Total number of outer attack iterations.\n        p_step (float): Initial probability of a pixel being modified in a square.\n                        This effectively controls the initial size of the square patch relative to total image size.\n        kappa (float): Confidence parameter. The attack tries to make the target class's\n                       logit score be at least 'kappa' higher than the maximum logit of all\n                       other classes. A lower 'kappa' (e.g., 0) means just misclassify.\n\n    Returns:\n        np.array: The adversarial example (perturbed input) if successful, otherwise None.\n    \"\"\"\n    input_shape = original_input.shape\n    \n    # Assume input is a flattened square image (e.g., 64 features for 8x8 image)\n    # Determine side length if it's a square image for patch operations\n    side_length = int(np.sqrt(num_features))\n    if side_length * side_length != num_features:\n        raise ValueError(\"Input features must represent a square image for this Square Attack implementation.\")\n\n    # Initialize adversarial example with noise or original input\n    # Starting with a random image (within epsilon budget) can sometimes help\n    # Or, start with the original input and iteratively add perturbations\n    x_adv = np.copy(original_input)\n    # Initially, ensure x_adv is within epsilon budget from original_input\n    # by adding random noise\n    random_noise = (np.random.rand(*input_shape) * 2 - 1) * epsilon\n    x_adv = np.clip(original_input + random_noise, 0, 1)\n\n    # --- Objective Function ---\n    def f_objective(current_x_candidate):\n        \"\"\"\n        Calculates the objective value. Lower value means better for attack.\n        We want to minimize max(max_{i!=target}(Z_i) - Z_target, -kappa)\n        \"\"\"\n        current_x_clipped = np.clip(current_x_candidate, 0, 1)\n        probabilities = model.predict_proba(current_x_clipped.reshape(1, -1))[0]\n        probabilities = np.clip(probabilities, 1e-10, 1)\n        logits = np.log(probabilities)\n\n        target_logit = logits[target_class]\n        other_logits = np.delete(logits, target_class)\n        max_other_logit = np.max(other_logits)\n\n        # The loss for the attack. We want this to be negative for a successful attack.\n        return np.maximum(max_other_logit - target_logit, -kappa)\n\n    # Get initial objective value\n    min_objective_value = f_objective(x_adv)\n    best_x_adv = np.copy(x_adv)\n\n    print(f\"Starting Square Attack for {max_iterations} iterations...\")\n\n    for i in range(max_iterations):\n        # Calculate current perturbation from original\n        perturbation = x_adv - original_input\n        \n        # Calculate the current L-infinity norm of the perturbation\n        current_linf_norm = np.max(np.abs(perturbation))\n\n        # Determine the size of the square patch\n        # The paper suggests a side length 's' such that s*s pixels are updated.\n        # It's related to the probability p_step.\n        s = int(round(np.sqrt(p_step * num_features)))\n        s = max(1, s) # Ensure side length is at least 1\n\n        # Randomly choose a top-left corner for the square patch\n        x_start = np.random.randint(0, side_length - s + 1) if side_length > s else 0\n        y_start = np.random.randint(0, side_length - s + 1) if side_length > s else 0\n\n        # Create a mask for the square region\n        patch_mask = np.zeros(input_shape).reshape(side_length, side_length)\n        patch_mask[y_start:y_start+s, x_start:x_start+s] = 1\n        patch_mask = patch_mask.flatten()\n\n        # Generate random noise for the patch, respecting epsilon budget\n        # Noise values are in [-1, 1], then scaled by epsilon\n        random_patch_noise = (np.random.rand(*input_shape) * 2 - 1) * epsilon * patch_mask\n\n        # Apply the proposed perturbation\n        x_adv_candidate = np.copy(original_input + perturbation * (1 - patch_mask) + random_patch_noise)\n        \n        # Clip values to [0, 1]\n        x_adv_candidate = np.clip(x_adv_candidate, 0, 1)\n        \n        # Evaluate the candidate adversarial example\n        candidate_objective_value = f_objective(x_adv_candidate)\n\n        # If the candidate improves the objective, accept it\n        if candidate_objective_value < min_objective_value:\n            min_objective_value = candidate_objective_value\n            x_adv = np.copy(x_adv_candidate) # Update current adversarial example\n            \n            # If the current prediction matches the target, this is a successful candidate\n            current_pred_candidate = model.predict(x_adv.reshape(1, -1))[0]\n            if current_pred_candidate == target_class:\n                best_x_adv = np.copy(x_adv) # Store this successful one\n\n        # Print progress\n        if (i + 1) % (max_iterations // 10) == 0 or i == 0:\n            current_pred = model.predict(x_adv.reshape(1, -1))[0]\n            current_l2_dist = np.linalg.norm(x_adv - original_input)\n            print(f\"Iteration {i+1}/{max_iterations}: Current Pred: {current_pred}, L2 Dist: {current_l2_dist:.4f}, Obj: {min_objective_value:.4f}\")\n            if current_pred == target_class:\n                print(f\"  Target class {target_class} reached!\")\n\n    # --- Final Check and Return ---\n    if best_x_adv is not None:\n        final_pred_class = model.predict(best_x_adv.reshape(1, -1))[0]\n        if final_pred_class == target_class:\n            final_l2_dist = np.linalg.norm(best_x_adv - original_input)\n            final_linf_norm = np.max(np.abs(best_x_adv - original_input))\n            print(f\"\\nSquare Attack successful! Adversarial example found. Final L2 Dist: {final_l2_dist:.4f}, L-inf Dist: {final_linf_norm:.4f}\")\n            return best_x_adv\n        else:\n            print(f\"\\nSquare Attack found a candidate, but final check predicts {final_pred_class} (expected {target_class}).\")\n            return None\n    else:\n        print(f\"\\nSquare Attack finished, but target class {target_class} not achieved within the iterations.\")\n        return None\n\n# --- Example Usage with an Actual Model (MLPClassifier on Digits Dataset) ---\nif __name__ == \"__main__\":\n    np.random.seed(42) # Set seed for reproducibility of model training and sample selection\n\n    print(\"--- Loading and Training MLPClassifier on Digits Dataset ---\")\n    digits = load_digits()\n    X, y = digits.data, digits.target\n    num_features = X.shape[1] # Number of features (64 for 8x8 images)\n\n    scaler = MinMaxScaler()\n    X_scaled = scaler.fit_transform(X)\n\n    X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)\n\n    # Train an MLPClassifier to act as our \"black-box\" model\n    mlp_model = MLPClassifier(hidden_layer_sizes=(100, 50), max_iter=500, random_state=1, verbose=False)\n    mlp_model.fit(X_train, y_train)\n    print(f\"Model training complete. Test accuracy: {mlp_model.score(X_test, y_test):.4f}\\n\")\n\n    # Select a random sample from the test set to attack\n    sample_index = np.random.randint(0, len(X_test))\n    original_sample = X_test[sample_index]\n    original_label = y_test[sample_index]\n\n    original_predicted_class = mlp_model.predict(original_sample.reshape(1, -1))[0]\n    original_probabilities = mlp_model.predict_proba(original_sample.reshape(1, -1))[0]\n    original_logits = np.log(np.clip(original_probabilities, 1e-10, 1))\n\n    print(\"--- Original Sample Details ---\")\n    print(f\"Original Label: {original_label}\")\n    print(f\"Model's Predicted Class: {original_predicted_class}\")\n    print(f\"Model's Logits: {original_logits.round(4)}\")\n    print(f\"Input Shape: {original_sample.shape}\\n\")\n\n    # Define the target class for the attack.\n    if original_predicted_class == original_label:\n        all_classes = np.arange(mlp_model.n_outputs_)\n        other_classes = all_classes[all_classes != original_label]\n        if len(other_classes) > 0:\n            target_class_for_attack = np.random.choice(other_classes)\n            print(f\"Original prediction is CORRECT ({original_label}). Attempting Square Attack to misclassify to Target Class: {target_class_for_attack}\\n\")\n        else:\n            print(\"Only one class, cannot perform targeted attack.\")\n            exit()\n    else:\n        target_class_for_attack = (original_predicted_class + 1) % mlp_model.n_outputs_\n        print(f\"Original prediction is INCORRECT ({original_predicted_class}). Attempting Square Attack to misclassify to Target Class: {target_class_for_attack}\\n\")\n\n\n    # --- Run the Square attack ---\n    # NOTE: Hyperparameters for Square Attack can be sensitive.\n    # Increasing max_iterations usually helps convergence.\n    # Epsilon budget controls visible perturbation.\n    # p_step influences patch size (smaller p_step means smaller, more frequent patches).\n    adversarial_sample = square_attack(\n        mlp_model,\n        original_sample,\n        target_class_for_attack,\n        epsilon=0.1,          # L-infinity budget\n        max_iterations=5000,  # Typically needs many iterations\n        p_step=0.1,           # Initial patch size proportion (e.g., 10% of features)\n        kappa=0.0             # 0 for basic misclassification\n    )\n\n    # --- Display results if an adversarial example was found ---\n    if adversarial_sample is not None:\n        adv_predicted_class = mlp_model.predict(adversarial_sample.reshape(1, -1))[0]\n        adv_probabilities = mlp_model.predict_proba(adversarial_sample.reshape(1, -1))[0]\n        adv_logits = np.log(np.clip(adv_probabilities, 1e-10, 1))\n        \n        perturbation = adversarial_sample - original_sample\n        l2_norm_perturbation = np.linalg.norm(perturbation)\n        linf_norm_perturbation = np.max(np.abs(perturbation))\n\n        print(\"\\n--- Square Attack Results ---\")\n        print(f\"Adversarial Input (first 5 features): {adversarial_sample[:5].round(4)}...\")\n        print(f\"Adversarial Logits: {adv_logits.round(4)}\")\n        print(f\"Adversarial Predicted Class: {adv_predicted_class}\")\n        print(f\"Perturbation (L2 Norm): {l2_norm_perturbation:.6f}\")\n        print(f\"Perturbation (L-inf Norm): {linf_norm_perturbation:.6f}\")\n\n\n        if adv_predicted_class == target_class_for_attack:\n            print(\"\\nSquare attack successful: The adversarial example is now classified as the target class!\")\n        else:\n            print(\"\\nSquare attack inconclusive: Adversarial example found, but not classified as the exact target class.\")\n    else:\n        print(\"\\nSquare attack failed to generate a suitable adversarial example.\")\n\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-06-28T14:03:38.261057Z","iopub.execute_input":"2025-06-28T14:03:38.261437Z","iopub.status.idle":"2025-06-28T14:03:43.632832Z","shell.execute_reply.started":"2025-06-28T14:03:38.261410Z","shell.execute_reply":"2025-06-28T14:03:43.631842Z"}},"outputs":[{"name":"stdout","text":"--- Loading and Training MLPClassifier on Digits Dataset ---\nModel training complete. Test accuracy: 0.9833\n\n--- Original Sample Details ---\nOriginal Label: 5\nModel's Predicted Class: 5\nModel's Logits: [-13.3782 -19.7226 -23.0259 -21.2603 -13.1114  -0.     -22.9556 -12.0312\n -22.2829 -10.7736]\nInput Shape: (64,)\n\nOriginal prediction is CORRECT (5). Attempting Square Attack to misclassify to Target Class: 3\n\nStarting Square Attack for 5000 iterations...\nIteration 1/5000: Current Pred: 5, L2 Dist: 0.3907, Obj: 22.6438\nIteration 500/5000: Current Pred: 5, L2 Dist: 0.4810, Obj: 14.3884\nIteration 1000/5000: Current Pred: 5, L2 Dist: 0.5015, Obj: 13.9494\nIteration 1500/5000: Current Pred: 5, L2 Dist: 0.5272, Obj: 13.7525\nIteration 2000/5000: Current Pred: 5, L2 Dist: 0.5095, Obj: 13.3506\nIteration 2500/5000: Current Pred: 5, L2 Dist: 0.5106, Obj: 13.2756\nIteration 3000/5000: Current Pred: 5, L2 Dist: 0.5178, Obj: 13.1395\nIteration 3500/5000: Current Pred: 5, L2 Dist: 0.5178, Obj: 13.1395\nIteration 4000/5000: Current Pred: 5, L2 Dist: 0.5178, Obj: 13.1395\nIteration 4500/5000: Current Pred: 5, L2 Dist: 0.5178, Obj: 13.1395\nIteration 5000/5000: Current Pred: 5, L2 Dist: 0.5343, Obj: 13.1090\n\nSquare Attack found a candidate, but final check predicts 5 (expected 3).\n\nSquare attack failed to generate a suitable adversarial example.\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}