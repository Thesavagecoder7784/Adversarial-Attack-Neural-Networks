{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[],"dockerImageVersionId":31040,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torch.optim as optim\nfrom torchvision import datasets, transforms\n# import matplotlib.pyplot as plt # Removed matplotlib for no image display\nimport numpy as np\n\n# --- 1. Define a Simple CNN Model ---\nclass SimpleCNN(nn.Module):\n    def __init__(self):\n        super(SimpleCNN, self).__init__()\n        # Input: 1 channel (grayscale), output: 10 channels (for 10 digits)\n        self.conv1 = nn.Conv2d(1, 10, kernel_size=5) # Output: (N, 10, 24, 24)\n        self.conv2 = nn.Conv2d(10, 20, kernel_size=5) # Output: (N, 20, 8, 8)\n        self.conv2_drop = nn.Dropout2d()\n        self.fc1 = nn.Linear(320, 50) # 20 * 4 * 4 = 320\n        self.fc2 = nn.Linear(50, 10)\n\n    def forward(self, x):\n        x = F.relu(F.max_pool2d(self.conv1(x), 2))\n        x = F.relu(F.max_pool2d(self.conv2_drop(self.conv2(x)), 2))\n        x = x.view(-1, 320) # Flatten the tensor for the fully connected layers\n        x = F.relu(self.fc1(x))\n        x = F.dropout(x, training=self.training)\n        x = self.fc2(x)\n        return F.log_softmax(x, dim=1) # Output log probabilities\n\n# --- 2. Load and Train Model (or load pre-trained) ---\ndef train_model(model, device, train_loader, optimizer, epochs=5):\n    model.train()\n    for epoch in range(epochs):\n        for batch_idx, (data, target) in enumerate(train_loader):\n            data, target = data.to(device), target.to(device)\n            optimizer.zero_grad()\n            output = model(data)\n            loss = F.nll_loss(output, target) # Negative Log Likelihood Loss\n            loss.backward()\n            optimizer.step()\n            if batch_idx % 100 == 0:\n                print(f'Train Epoch: {epoch} [{batch_idx * len(data)}/{len(train_loader.dataset)} '\n                      f'({100. * batch_idx / len(train_loader):.0f}%)]\\tLoss: {loss.item():.6f}')\n\ndef test_model(model, device, test_loader):\n    model.eval()\n    test_loss = 0\n    correct = 0\n    with torch.no_grad():\n        for data, target in test_loader:\n            data, target = data.to(device), target.to(device)\n            output = model(data)\n            test_loss += F.nll_loss(output, target, reduction='sum').item() # sum up batch loss\n            pred = output.argmax(dim=1, keepdim=True) # get the index of the max log-probability\n            correct += pred.eq(target.view_as(pred)).sum().item()\n\n    test_loss /= len(test_loader.dataset)\n    print(f'\\nTest set: Average loss: {test_loss:.4f}, Accuracy: {correct}/{len(test_loader.dataset)} '\n          f'({100. * correct / len(test_loader.dataset):.0f}%)\\n')\n\n\n# --- 3. Implement MI-FGSM Attack ---\ndef mi_fgsm_attack(model, image, true_label, epsilon, alpha, iterations, decay=1.0):\n    \"\"\"\n    Implements the Momentum Iterative Fast Gradient Sign Method (MI-FGSM) attack.\n\n    Args:\n        model (nn.Module): The target classification model.\n        image (torch.Tensor): The original input image (tensor).\n        true_label (torch.Tensor): The true label of the original image.\n        epsilon (float): The maximum total perturbation allowed (L-infinity norm).\n        alpha (float): The step size for each iteration.\n        iterations (int): The number of iterations for the attack.\n        decay (float): Decay factor for the momentum (rho in papers), default 1.0 (no decay).\n\n    Returns:\n        torch.Tensor: The adversarial image.\n    \"\"\"\n    # Set model to evaluation mode\n    model.eval()\n\n    # Clone the image and enable gradient calculation for it\n    x_adv = image.clone().detach().requires_grad_(True)\n    \n    # Initialize momentum\n    momentum = torch.zeros_like(image, device=image.device)\n\n    for i in range(iterations):\n        # Forward pass: get model output\n        output = model(x_adv)\n        \n        # Calculate loss (untargeted attack: maximize loss for true label)\n        # If performing a targeted attack, the loss function would be different,\n        # e.g., maximizing the logit of the target class while minimizing others.\n        loss = F.nll_loss(output, true_label)\n        \n        # Zero previous gradients\n        model.zero_grad()\n        \n        # Compute gradients of loss w.r.t. x_adv\n        loss.backward()\n        \n        # Get the gradient data\n        grad = x_adv.grad.data\n\n        # Normalize the gradient by its L1 norm (as per MI-FGSM)\n        # Add a small epsilon to the denominator to avoid division by zero\n        grad_norm = F.normalize(grad, p=1) \n        \n        # Update momentum\n        momentum = decay * momentum + grad_norm\n\n        # Apply perturbation in the direction of the sign of momentum\n        # and clip the perturbation by alpha for each step\n        x_adv_new = x_adv.data + alpha * torch.sign(momentum)\n        \n        # Clip the adversarial image to stay within the epsilon bounds relative to original\n        # This ensures the total perturbation doesn't exceed epsilon\n        perturbation = x_adv_new - image.data\n        x_adv.data = image.data + torch.clamp(perturbation, -epsilon, epsilon)\n        \n        # Clip the adversarial image to valid pixel range [0, 1]\n        x_adv.data = torch.clamp(x_adv.data, 0, 1)\n        \n        # Detach x_adv.grad for the next iteration to prevent graph accumulation\n        if x_adv.grad is not None:\n            x_adv.grad.zero_()\n            \n    return x_adv\n\n# --- 4. Main Execution and Visualization ---\nif __name__ == \"__main__\":\n    # --- Configuration ---\n    # Check if GPU is available\n    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n    print(f\"Using device: {device}\")\n\n    # Dataset transformation: Convert to Tensor, Normalize (for MNIST)\n    transform = transforms.Compose([\n        transforms.ToTensor(),\n        # MNIST images are typically normalized to [-1, 1] or [0, 1].\n        # For simplicity in attack, we'll work with [0, 1] and then clip.\n        # So, no explicit normalization to mean/std for now.\n        # transforms.Normalize((0.1307,), (0.3081,)) # Standard MNIST normalization\n    ])\n\n    # Load MNIST dataset\n    train_loader = torch.utils.data.DataLoader(\n        datasets.MNIST('../data', train=True, download=True, transform=transform),\n        batch_size=64, shuffle=True\n    )\n    test_loader = torch.utils.data.DataLoader(\n        datasets.MNIST('../data', train=False, transform=transform),\n        batch_size=1, shuffle=True # Batch size 1 for easy individual sample attack\n    )\n\n    # Initialize and train the model\n    model = SimpleCNN().to(device)\n    optimizer = optim.Adam(model.parameters(), lr=0.001)\n\n    # You can load a pre-trained model here to skip training:\n    # try:\n    #     model.load_state_dict(torch.load('mnist_cnn_mi_fgsm.pt'))\n    #     print(\"Loaded pre-trained model.\")\n    # except FileNotFoundError:\n    #     print(\"Pre-trained model not found. Training new model...\")\n    #     train_model(model, device, train_loader, optimizer, epochs=5)\n    #     torch.save(model.state_dict(), 'mnist_cnn_mi_fgsm.pt') # Save after training\n\n    # For demonstration, let's train for a few epochs if no model is found\n    print(\"Training model...\")\n    train_model(model, device, train_loader, optimizer, epochs=3) # Train for 3 epochs\n    test_model(model, device, test_loader)\n    print(\"Model training/loading complete.\")\n\n    # --- Attack Parameters ---\n    epsilon = 0.2    # Total perturbation budget (e.g., 0.2 means max 20% change in pixel value)\n    alpha = 0.02     # Step size for each iteration (should be < epsilon)\n    iterations = 20  # Number of attack iterations\n    decay = 1.0      # Momentum decay factor (1.0 for no decay)\n\n    # --- Select a sample to attack ---\n    # Find a sample that the model initially classifies correctly\n    original_image, true_label = None, None\n    for data, target in test_loader:\n        data, target = data.to(device), target.to(device)\n        output = model(data)\n        initial_pred = output.argmax(dim=1, keepdim=True)\n        if initial_pred.item() == target.item():\n            original_image = data\n            true_label = target\n            break\n    \n    if original_image is None:\n        print(\"Could not find a correctly classified sample to attack. Exiting.\")\n        exit()\n\n    print(f\"Attacking image with true label: {true_label.item()}\")\n    \n    # --- Run MI-FGSM Attack ---\n    adversarial_image = mi_fgsm_attack(model, original_image, true_label, epsilon, alpha, iterations, decay)\n\n    # --- Evaluate Adversarial Example ---\n    model.eval()\n    with torch.no_grad():\n        original_output = model(original_image)\n        original_pred = original_output.argmax(dim=1, keepdim=True).item()\n        \n        adversarial_output = model(adversarial_image)\n        adversarial_pred = adversarial_output.argmax(dim=1, keepdim=True).item()\n\n    print(f\"\\nOriginal Prediction: {original_pred}\")\n    print(f\"Adversarial Prediction: {adversarial_pred}\")\n\n    if original_pred != adversarial_pred:\n        print(f\"\\nMI-FGSM attack successfully changed prediction from {original_pred} to {adversarial_pred}\")\n    else:\n        print(\"\\nMI-FGSM attack did NOT change the prediction.\")\n\n","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-06-26T16:09:56.015956Z","iopub.execute_input":"2025-06-26T16:09:56.016286Z","iopub.status.idle":"2025-06-26T16:11:00.424836Z","shell.execute_reply.started":"2025-06-26T16:09:56.016260Z","shell.execute_reply":"2025-06-26T16:11:00.423874Z"}},"outputs":[{"name":"stdout","text":"Using device: cpu\nTraining model...\nTrain Epoch: 0 [0/60000 (0%)]\tLoss: 2.317826\nTrain Epoch: 0 [6400/60000 (11%)]\tLoss: 1.014071\nTrain Epoch: 0 [12800/60000 (21%)]\tLoss: 0.689047\nTrain Epoch: 0 [19200/60000 (32%)]\tLoss: 0.546001\nTrain Epoch: 0 [25600/60000 (43%)]\tLoss: 0.548565\nTrain Epoch: 0 [32000/60000 (53%)]\tLoss: 0.460259\nTrain Epoch: 0 [38400/60000 (64%)]\tLoss: 0.340495\nTrain Epoch: 0 [44800/60000 (75%)]\tLoss: 0.338955\nTrain Epoch: 0 [51200/60000 (85%)]\tLoss: 0.221854\nTrain Epoch: 0 [57600/60000 (96%)]\tLoss: 0.234711\nTrain Epoch: 1 [0/60000 (0%)]\tLoss: 0.343618\nTrain Epoch: 1 [6400/60000 (11%)]\tLoss: 0.253925\nTrain Epoch: 1 [12800/60000 (21%)]\tLoss: 0.610684\nTrain Epoch: 1 [19200/60000 (32%)]\tLoss: 0.223054\nTrain Epoch: 1 [25600/60000 (43%)]\tLoss: 0.447782\nTrain Epoch: 1 [32000/60000 (53%)]\tLoss: 0.272211\nTrain Epoch: 1 [38400/60000 (64%)]\tLoss: 0.280039\nTrain Epoch: 1 [44800/60000 (75%)]\tLoss: 0.271009\nTrain Epoch: 1 [51200/60000 (85%)]\tLoss: 0.227587\nTrain Epoch: 1 [57600/60000 (96%)]\tLoss: 0.176433\nTrain Epoch: 2 [0/60000 (0%)]\tLoss: 0.234688\nTrain Epoch: 2 [6400/60000 (11%)]\tLoss: 0.531842\nTrain Epoch: 2 [12800/60000 (21%)]\tLoss: 0.228839\nTrain Epoch: 2 [19200/60000 (32%)]\tLoss: 0.180715\nTrain Epoch: 2 [25600/60000 (43%)]\tLoss: 0.310849\nTrain Epoch: 2 [32000/60000 (53%)]\tLoss: 0.228253\nTrain Epoch: 2 [38400/60000 (64%)]\tLoss: 0.256608\nTrain Epoch: 2 [44800/60000 (75%)]\tLoss: 0.129954\nTrain Epoch: 2 [51200/60000 (85%)]\tLoss: 0.288339\nTrain Epoch: 2 [57600/60000 (96%)]\tLoss: 0.148434\n\nTest set: Average loss: 0.0714, Accuracy: 9771/10000 (98%)\n\nModel training/loading complete.\nAttacking image with true label: 4\n\nOriginal Prediction: 4\nAdversarial Prediction: 9\n\nMI-FGSM attack successfully changed prediction from 4 to 9\n","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}